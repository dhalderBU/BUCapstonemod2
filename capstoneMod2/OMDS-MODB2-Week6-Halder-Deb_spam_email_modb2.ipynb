{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:55.676201Z",
     "start_time": "2025-04-17T06:42:55.673060Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Working on your datasets\n",
    "\n",
    "This week, you will do the same types of exercises as last week, but you should use your chosen datasets that someone in your class found last semester. (They likely will not be the particular datasets that you found yourself.)\n",
    "\n",
    "### Here are some types of analysis you can do:\n",
    "\n",
    "- Find correlations between pairs of variables.\n",
    "\n",
    "- Draw scatterplots, especially when the correlation is large.\n",
    "\n",
    "- Draw pairplots.\n",
    "\n",
    "- Draw line graphs and/or area graphs when there is date or time data together with numerical data.\n",
    "\n",
    "### Conclusions:\n",
    "\n",
    "- Explain what conclusions you would draw from this analysis: are the data what you expect?  Are the data likely to be usable?  If the data are not useable, find some new data!\n",
    "\n",
    "- Do you see any outliers?  (Data points that are far from the rest of the data).\n",
    "\n",
    "- Are any data items highly correlated with each other, suggesting that they are redundant?\n",
    "\n",
    "- For the line plots, do you see a trend or pattern over time?  Does this suggest that the data are changing over time (drifting) in such a way as to invalidate comparisons?\n",
    "\n",
    "- Can you think of any confounding variables?  (Third variables that could explain any correlations between other variables.  These third variables may or may not be reported in the dataset.)"
   ],
   "id": "4ab39194a118f3bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Since there was conflicting message on the homework 6 I have done the assigned dataset in this semester as a separate notebook and adding the link in the main homework notebook\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "\n",
    "- Explain what conclusions you would draw from this analysis: are the data what you expect?  Are the data likely to be usable?  If the data are not useable, find some new data!\n",
    "\n",
    "The data is very good and highly relevant. We needed to do data-wrangling before I started extracting features for m the email text I found the ata highly useful.\n",
    "\n",
    "The correlation matrix shows that the extracted features word count, urgency , threat, financial terms  are having moderate correlation  for this kind of problem.There cases where unsafe emails have higher http count and more needs to be analyzed.\n",
    "\n",
    "The dataset for the email phishing only had three column which one was the feature - email text and the other was target i.e. type. So as to analyse I had to use the NLTK library to parse the mails and create features from the data. The features that I created were\n",
    "\n",
    "- 1   http_url_count\n",
    "\n",
    "- 2   https_url_count\n",
    "\n",
    "- 3   sentence_count\n",
    "\n",
    "- 4   total_word_count\n",
    "\n",
    "- 5   urgency_terms_count\n",
    "\n",
    "- 6   account_terms_count\n",
    "\n",
    "- 7   threat_terms_count\n",
    "\n",
    "- 8   financial_terms_count\n",
    "\n",
    "- 9   official_terms_count\n",
    "\n",
    "The Dataset was not balanced and the analysis of the whole dataset gave me incrrect corelation. but when I created a balanced smaller data with 5)5 spam and non spam I got much better results. I was able to do analysis on a smaller dataset which was completing the analysis much quicker. I took help from ChatGPT and Google as I didnt work on NLTK before. I also researched on how spam email works and created my own workflow for the EDA.\n",
    "\n",
    "### Do you see any outliers?  (Data points that are far from the rest of the data).)\n",
    "\n",
    "The data is usable and any one should create a balanced dataset to do the analysis.\n",
    "\n",
    "There are outliers in many of the columns and the same is evident from the box plot as there are circle(o) markers in many of the box plot which are outside the inter-quartile range. There extracted features  like frequency of use if account related word, threat related word or urgency related words. We did not notice a strong correlation that one single feature could identify a spam. It looks like it will be combination of features which we will need to use\n",
    "\n",
    "### Are any data items highly correlated with each other, suggesting that they are redundant?\n",
    "\n",
    "The sentence_count and total_word_count show a perfect correlation (greater than 0.9), indicating they are redundant features and we could drop one of them\n",
    "\n",
    "### For the line plots, do you see a trend or pattern over time?  Does this suggest that the data are changing over time (drifting) in such a way as to invalidate comparisons?\n",
    "\n",
    "For this dataset there was no such as the data was email text and didnt have the date\n",
    "\n",
    "\n",
    "### Can you think of any confounding variables?  (Third variables that could explain any correlations between other variables.  These third variables may or may not be reported in the dataset.)\n",
    "\n",
    "For this dataset only text and the target variable was provided so we we had to extract the dataset. The other two datasets could have confounding variables (Phishing website containing URL info) and ICSA Vulnerability could also bring in additional information that could be used as confounding variable\n",
    "\n"
   ],
   "id": "4db265973aaf184a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.076703Z",
     "start_time": "2025-04-17T06:42:55.683584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import dataset file \"web_page_dataset_phishing.csv\" from folder./Phishing_data\n",
    "path = './dataset/'\n",
    "os.listdir(path)\n",
    "\n",
    "#first open the two datasets related to phishing_website and phishing_email\n",
    "\n",
    "#df_phishing_website_data=pd.read_csv(path+'web_page_dataset_phishing.csv')\n",
    "df_phishing_email_data=pd.read_csv(path+'phishing_email.csv')"
   ],
   "id": "e22d7b1b5f09fa49",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.089913Z",
     "start_time": "2025-04-17T06:42:56.084257Z"
    }
   },
   "cell_type": "code",
   "source": "df_phishing_email_data.describe()",
   "id": "89ab7ae4457ceea4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Unnamed: 0\n",
       "count  18650.000000\n",
       "mean    9325.154477\n",
       "std     5384.327293\n",
       "min        0.000000\n",
       "25%     4662.250000\n",
       "50%     9325.500000\n",
       "75%    13987.750000\n",
       "max    18650.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9325.154477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5384.327293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4662.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9325.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13987.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.117836Z",
     "start_time": "2025-04-17T06:42:56.112316Z"
    }
   },
   "cell_type": "code",
   "source": "df_phishing_email_data.info()\n",
   "id": "fd665b9f47c2ff6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18650 entries, 0 to 18649\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  18650 non-null  int64 \n",
      " 1   Email Text  18634 non-null  object\n",
      " 2   Email Type  18650 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 437.2+ KB\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### lets look at the phishing_email_dataset\n",
   "id": "d201243c175d1d6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.144037Z",
     "start_time": "2025-04-17T06:42:56.137304Z"
    }
   },
   "cell_type": "code",
   "source": "df_phishing_email_data.head(50)",
   "id": "87c460efc310173f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0                                         Email Text  \\\n",
       "0            0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
       "1            1  the other side of * galicismos * * galicismo *...   \n",
       "2            2  re : equistar deal tickets are you still avail...   \n",
       "3            3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
       "4            4  software at incredibly low prices ( 86 % lower...   \n",
       "5            5  global risk management operations sally congra...   \n",
       "6            6  On Sun, Aug 11, 2002 at 11:17:47AM +0100, wint...   \n",
       "7            7  entourage , stockmogul newsletter ralph velez ...   \n",
       "8            8  we owe you lots of money dear applicant , afte...   \n",
       "9            9  re : coastal deal - with exxon participation u...   \n",
       "10          10  make her beg you to give it to her everynight ...   \n",
       "11          11  URL: http://www.newsisfree.com/click/-5,830431...   \n",
       "12          12  begin forwarded text Date: Wed, 25 Sep 2002 13...   \n",
       "13          13  re : fyi - wellhead portfolio who is considere...   \n",
       "14          14  rmmla / ads * * * * * * * * papers solicited f...   \n",
       "15          15  re : testing ir & fx var nick and winston , i ...   \n",
       "16          16  The academic discipline of Software Engineerin...   \n",
       "17          17  re : 3 . 402 queries : language - speakers , s...   \n",
       "18          18  a resume john , this is a resume i received to...   \n",
       "19          19  EFFector       Vol. 15, No. 35       November ...   \n",
       "20          20  re : meeting on feb 8 , 2001 dear mr . nur azm...   \n",
       "21          21  formal invite for chase . secrets revealed . h...   \n",
       "22          22  \\nQuestion?Do you want a different job?\\nDo yo...   \n",
       "23          23  URL: http://www.livejournal.com/talkread.bml?j...   \n",
       "24          24  calpine daily and monthly nomination > > ricky...   \n",
       "25          25  fw : bod agenda deadlines the next bod and com...   \n",
       "26          26  start date : 12 / 16 / 01 ; hourahead hour : 1...   \n",
       "27          27  re : tetco / hpl ( enerfin ) meter # 986892 st...   \n",
       "28          28  \\nPROMOTE YOUR PRODUCT OR\\nSERVICE TO MILLIONS...   \n",
       "29          29  culture committee / subcommittee meeting the m...   \n",
       "30          30  sle 31 call for papers , sle 31 , st andrews ,...   \n",
       "31          31                                                NaN   \n",
       "32          32  lowers blood pressure and cholesterol let ' s ...   \n",
       "33          33  release of agfl home page this message announc...   \n",
       "34          34  mobil beaumont - marol just want to confirm th...   \n",
       "35          35  <!--\\nfunction MM_findObj(n, d) { //v3.0\\n  va...   \n",
       "36          36  presentation on metals - - - - - - - - - - - -...   \n",
       "37          37  premium adult content looking for high quality...   \n",
       "38          38  Thanks Brent: now it's clearer (to me) what's ...   \n",
       "39          39  re : 6 . 381 words that are their own opposite...   \n",
       "40          40  25 mg trick how to save on your medlcations ov...   \n",
       "41          41  Help wanted.  We are a 14 year old fortune 500...   \n",
       "42          42  important message jaguar are anaerobic is brut...   \n",
       "43          43  hpl optimization team , as i mentioned in our ...   \n",
       "44          44  Pity.  Reading that woman's ad and knowing Roh...   \n",
       "45          45  BUY 2 ADULT DVDs AT REGULAR PRICE AND GET A TH...   \n",
       "46          46  re : fw : first deliveries - comstock oil & ga...   \n",
       "47          47  new hire dinner rsvps don ' t forget to let me...   \n",
       "48          48  gino , who do u want to win ? the secret on ho...   \n",
       "49          49  unbelievable new homes for the usa ! it ' s a ...   \n",
       "\n",
       "        Email Type  \n",
       "0       Safe Email  \n",
       "1       Safe Email  \n",
       "2       Safe Email  \n",
       "3   Phishing Email  \n",
       "4   Phishing Email  \n",
       "5       Safe Email  \n",
       "6       Safe Email  \n",
       "7   Phishing Email  \n",
       "8   Phishing Email  \n",
       "9       Safe Email  \n",
       "10  Phishing Email  \n",
       "11      Safe Email  \n",
       "12      Safe Email  \n",
       "13      Safe Email  \n",
       "14      Safe Email  \n",
       "15      Safe Email  \n",
       "16      Safe Email  \n",
       "17      Safe Email  \n",
       "18      Safe Email  \n",
       "19      Safe Email  \n",
       "20      Safe Email  \n",
       "21  Phishing Email  \n",
       "22  Phishing Email  \n",
       "23      Safe Email  \n",
       "24      Safe Email  \n",
       "25      Safe Email  \n",
       "26      Safe Email  \n",
       "27      Safe Email  \n",
       "28  Phishing Email  \n",
       "29      Safe Email  \n",
       "30      Safe Email  \n",
       "31  Phishing Email  \n",
       "32  Phishing Email  \n",
       "33      Safe Email  \n",
       "34      Safe Email  \n",
       "35  Phishing Email  \n",
       "36      Safe Email  \n",
       "37  Phishing Email  \n",
       "38      Safe Email  \n",
       "39      Safe Email  \n",
       "40  Phishing Email  \n",
       "41  Phishing Email  \n",
       "42  Phishing Email  \n",
       "43      Safe Email  \n",
       "44      Safe Email  \n",
       "45  Phishing Email  \n",
       "46      Safe Email  \n",
       "47      Safe Email  \n",
       "48  Phishing Email  \n",
       "49  Phishing Email  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>global risk management operations sally congra...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>On Sun, Aug 11, 2002 at 11:17:47AM +0100, wint...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>entourage , stockmogul newsletter ralph velez ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>we owe you lots of money dear applicant , afte...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>re : coastal deal - with exxon participation u...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>make her beg you to give it to her everynight ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-5,830431...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>begin forwarded text Date: Wed, 25 Sep 2002 13...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>re : fyi - wellhead portfolio who is considere...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>rmmla / ads * * * * * * * * papers solicited f...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>re : testing ir &amp; fx var nick and winston , i ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>The academic discipline of Software Engineerin...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>re : 3 . 402 queries : language - speakers , s...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>a resume john , this is a resume i received to...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>EFFector       Vol. 15, No. 35       November ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>re : meeting on feb 8 , 2001 dear mr . nur azm...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>formal invite for chase . secrets revealed . h...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>\\nQuestion?Do you want a different job?\\nDo yo...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>URL: http://www.livejournal.com/talkread.bml?j...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>calpine daily and monthly nomination &gt; &gt; ricky...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>fw : bod agenda deadlines the next bod and com...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>start date : 12 / 16 / 01 ; hourahead hour : 1...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>re : tetco / hpl ( enerfin ) meter # 986892 st...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>\\nPROMOTE YOUR PRODUCT OR\\nSERVICE TO MILLIONS...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>culture committee / subcommittee meeting the m...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>sle 31 call for papers , sle 31 , st andrews ,...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>lowers blood pressure and cholesterol let ' s ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>release of agfl home page this message announc...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>mobil beaumont - marol just want to confirm th...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>&lt;!--\\nfunction MM_findObj(n, d) { //v3.0\\n  va...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>presentation on metals - - - - - - - - - - - -...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>premium adult content looking for high quality...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Thanks Brent: now it's clearer (to me) what's ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>re : 6 . 381 words that are their own opposite...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>25 mg trick how to save on your medlcations ov...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Help wanted.  We are a 14 year old fortune 500...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>important message jaguar are anaerobic is brut...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>hpl optimization team , as i mentioned in our ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Pity.  Reading that woman's ad and knowing Roh...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>BUY 2 ADULT DVDs AT REGULAR PRICE AND GET A TH...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>re : fw : first deliveries - comstock oil &amp; ga...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>new hire dinner rsvps don ' t forget to let me...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>gino , who do u want to win ? the secret on ho...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>unbelievable new homes for the usa ! it ' s a ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.174044Z",
     "start_time": "2025-04-17T06:42:56.170654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check if Unnamed column is having the same value as the index\n",
    "df_phishing_email_data['Unnamed: 0'].equals(df_phishing_email_data.index)"
   ],
   "id": "4acd054181f2acef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.204992Z",
     "start_time": "2025-04-17T06:42:56.199069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check which rows have different values in Unnamed column compared toi Index\n",
    "df_phishing_email_data[df_phishing_email_data['Unnamed: 0']!=df_phishing_email_data.index]\n"
   ],
   "id": "23d3e7b31fc4b06a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Unnamed: 0                                         Email Text  \\\n",
       "6444         6445  Dear Sir/MadamOur company is designer and manu...   \n",
       "6445         6446  synthetic compounds summary dear colleagues , ...   \n",
       "6446         6447  R. A. Hettinga:\\n>Church, AA, same diff?It's d...   \n",
       "6447         6448  On Thu, 25 Jul 2002, Joseph S. Barrera III wro...   \n",
       "6448         6449  fw : modified version lance , any comment ? vi...   \n",
       "...           ...                                                ...   \n",
       "18645       18646  date a lonely housewife always wanted to date ...   \n",
       "18646       18647  request submitted : access request for anita ....   \n",
       "18647       18648  re : important - prc mtg hi dorn & john , as y...   \n",
       "18648       18649  press clippings - letter on californian utilit...   \n",
       "18649       18650                                              empty   \n",
       "\n",
       "           Email Type  \n",
       "6444   Phishing Email  \n",
       "6445       Safe Email  \n",
       "6446       Safe Email  \n",
       "6447       Safe Email  \n",
       "6448       Safe Email  \n",
       "...               ...  \n",
       "18645  Phishing Email  \n",
       "18646      Safe Email  \n",
       "18647      Safe Email  \n",
       "18648      Safe Email  \n",
       "18649  Phishing Email  \n",
       "\n",
       "[12206 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>6445</td>\n",
       "      <td>Dear Sir/MadamOur company is designer and manu...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>6446</td>\n",
       "      <td>synthetic compounds summary dear colleagues , ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>6447</td>\n",
       "      <td>R. A. Hettinga:\\n&gt;Church, AA, same diff?It's d...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>6448</td>\n",
       "      <td>On Thu, 25 Jul 2002, Joseph S. Barrera III wro...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>6449</td>\n",
       "      <td>fw : modified version lance , any comment ? vi...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>18646</td>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>18647</td>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>18648</td>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>18649</td>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18649</th>\n",
       "      <td>18650</td>\n",
       "      <td>empty</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12206 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.235419Z",
     "start_time": "2025-04-17T06:42:56.232909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#rename the column name \"Email Text\" to `text` and \"Email Type\" to `type`\n",
    "df_phishing_email_data.rename(columns={'Email Text':'text','Email Type':'type'},inplace=True)"
   ],
   "id": "961b0bbe45f4441e",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### by looking at the data it it seems the Unnamed column is more of a serial number or index but doesnt have any value. So we can drop it",
   "id": "55aa59bc5d6f47d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.261738Z",
     "start_time": "2025-04-17T06:42:56.258465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#drop Unnamed column\n",
    "df_phishing_email_data.drop(columns=['Unnamed: 0'],inplace=True)"
   ],
   "id": "466062343cea43a5",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.276955Z",
     "start_time": "2025-04-17T06:42:56.271214Z"
    }
   },
   "cell_type": "code",
   "source": "df_phishing_email_data.info()",
   "id": "18a832a7414a3807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18650 entries, 0 to 18649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18634 non-null  object\n",
      " 1   type    18650 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 291.5+ KB\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.289012Z",
     "start_time": "2025-04-17T06:42:56.285919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check the shape of the data\n",
    "df_phishing_email_data.shape"
   ],
   "id": "e88b99b587892955",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18650, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### since there is only one feature and the other is the target(type) so let us extract some information from email text that we can then use as features and then we can analyze the data.\n",
    "\n",
    "based on the research on internet we understand that typically spam emails have call to action words and inorder to steal information it may direct people websites which are then used to steal information. So we will extract sentence count in each email, the word count in each email after dropping the stop words. We will then analyze the type of emails which are of type phishing email and identify the call to action words, we will identify if the email has links to URLs with https and without https .  We will do a word cloud of the email text for the spams and create a list of such words and then see the count of such words in spam and non spam emails. I also researched to see the NLTK library people are referreing to is punkt so I will use that"
   ],
   "id": "6bddba5eeba7fa7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.301387Z",
     "start_time": "2025-04-17T06:42:56.297304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lets get the value counts of the type of emails\n",
    "df_phishing_email_data['type'].value_counts()"
   ],
   "id": "347b038d0d9a526c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Safe Email        11322\n",
       "Phishing Email     7328\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.325066Z",
     "start_time": "2025-04-17T06:42:56.322850Z"
    }
   },
   "cell_type": "code",
   "source": "df = df_phishing_email_data.copy()",
   "id": "b41556d1acc55a6d",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.376928Z",
     "start_time": "2025-04-17T06:42:56.347856Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe()\n",
   "id": "c0909e4fdc118af3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         text        type\n",
       "count   18634       18650\n",
       "unique  17537           2\n",
       "top     empty  Safe Email\n",
       "freq      533       11322"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18634</td>\n",
       "      <td>18650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17537</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>empty</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>533</td>\n",
       "      <td>11322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.399909Z",
     "start_time": "2025-04-17T06:42:56.395151Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "c1e31359d2a1cadc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18650 entries, 0 to 18649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18634 non-null  object\n",
      " 1   type    18650 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 291.5+ KB\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.430405Z",
     "start_time": "2025-04-17T06:42:56.418682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the type column from text (Dtype = object to int and we will use the the first word (Safe = 0, Phishing = 1) as there could be spaces\n",
    "\n",
    "df['type'] = df['type'].apply(lambda x: 1 if x.split()[0] == 'Phishing' else 0)\n",
    "df.info()"
   ],
   "id": "27dcdca4828bcb12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18650 entries, 0 to 18649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18634 non-null  object\n",
      " 1   type    18650 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 291.5+ KB\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.449790Z",
     "start_time": "2025-04-17T06:42:56.446783Z"
    }
   },
   "cell_type": "code",
   "source": "df['type'].value_counts()",
   "id": "988397e8592a5f43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "0    11322\n",
       "1     7328\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.479972Z",
     "start_time": "2025-04-17T06:42:56.474302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#let us check if the text has only space or empty\n",
    "df[df['text'].isnull()].count()\n"
   ],
   "id": "121ced37ad2a194",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "type    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.533231Z",
     "start_time": "2025-04-17T06:42:56.526423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#let us check if the text has only space or empty\n",
    "\n",
    "\n",
    "df[df['text'].isnull()]"
   ],
   "id": "f3345bc8607c87df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      text  type\n",
       "31     NaN     1\n",
       "387    NaN     1\n",
       "1883   NaN     1\n",
       "2049   NaN     1\n",
       "2451   NaN     1\n",
       "2972   NaN     1\n",
       "3627   NaN     1\n",
       "3806   NaN     1\n",
       "5763   NaN     1\n",
       "6299   NaN     1\n",
       "6821   NaN     1\n",
       "8594   NaN     1\n",
       "9999   NaN     1\n",
       "11069  NaN     1\n",
       "11320  NaN     1\n",
       "13843  NaN     1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13843</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lets remove blank emails or email with only spaces",
   "id": "8d30934fdcde18f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.603398Z",
     "start_time": "2025-04-17T06:42:56.576061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first, let's check the initial number of rows\n",
    "print(\"Initial number of rows:\", len(df))\n",
    "\n",
    "# remove rows where text is empty or contains only whitespace\n",
    "df = df[df['text'].str.strip().str.len() > 0]\n",
    "\n",
    "# check the final number of rows\n",
    "print(\"Number of rows after cleaning:\", len(df))"
   ],
   "id": "82bbbf557263b52f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 18650\n",
      "Number of rows after cleaning: 18631\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.626420Z",
     "start_time": "2025-04-17T06:42:56.623540Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "77fca0c540092386",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18631, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### So there were 19 such rows which got removed",
   "id": "af8107793cd7eb94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.654152Z",
     "start_time": "2025-04-17T06:42:56.648767Z"
    }
   },
   "cell_type": "code",
   "source": "df[df['text'].isnull()]",
   "id": "db24ff6a5f498830",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, type]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:56.682017Z",
     "start_time": "2025-04-17T06:42:56.675944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ],
   "id": "22cb1229348d018b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18631 entries, 0 to 18630\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18631 non-null  object\n",
      " 1   type    18631 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 291.2+ KB\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:57.331197Z",
     "start_time": "2025-04-17T06:42:56.701455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets see if there are any http url in the email or https url. We will use regular expression and took help from the internet for the rules for the https and HTTPS pattern. Took help from chatgpt to understand how to use it\n",
    "\n",
    "import re\n",
    "def count_urls(text):\n",
    "    \"\"\"\n",
    "    Counts HTTP and HTTPS URLs in a given text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input text to analyze\n",
    "\n",
    "    Returns:\n",
    "    tuple: Count of (HTTP URLs, HTTPS URLs)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pattern for matching http:// and https:// URLs\n",
    "        http_pattern = r'http://[^\\s<>\"\\']+'\n",
    "        https_pattern = r'https://[^\\s<>\"\\']+'\n",
    "\n",
    "        # Count occurrences\n",
    "        http_count = len(re.findall(http_pattern, str(text)))\n",
    "        https_count = len(re.findall(https_pattern, str(text)))\n",
    "\n",
    "        return http_count, https_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return 0, 0\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['http_url_count', 'https_url_count']] = (\n",
    "    df['text'].apply(count_urls).apply(pd.Series)\n",
    ")"
   ],
   "id": "ebf5e07f1738f513",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:57.341628Z",
     "start_time": "2025-04-17T06:42:57.338489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('stopwords')  # For stop words\n",
    "\n",
    "# Import the specific functions you want to use\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ],
   "id": "3a035d520d7aec8b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/debasishhalder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/debasishhalder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:42:57.351930Z",
     "start_time": "2025-04-17T06:42:57.349281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lets count the sentences in each of the emails using NLTK sentence tokenizer. Took help from chatgpt to understand how to use it\n",
    "#import nltk\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "def count_sentences(text):\n",
    "    \"\"\"\n",
    "    Counts the number of sentences in a given text using NLTK's sentence tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input text to analyze\n",
    "\n",
    "    Returns:\n",
    "    int: Number of sentences in the text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle potential null values\n",
    "        text_str = str(text)\n",
    "\n",
    "        # Tokenize the text into sentences\n",
    "        sentences = sent_tokenize(text_str)\n",
    "        return len(sentences)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return 0"
   ],
   "id": "8af59d426aa3c8f",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:01.110632Z",
     "start_time": "2025-04-17T06:42:57.359021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# apply the function to create a new column sentence_count\n",
    "df['sentence_count'] = df['text'].apply(count_sentences)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Sentence count statistics:\")\n",
    "print(df['sentence_count'].describe())"
   ],
   "id": "a92ef0ca379f0759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence count statistics:\n",
      "count     18631.000000\n",
      "mean         32.229188\n",
      "std        1636.333244\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%           9.000000\n",
      "75%          19.000000\n",
      "max      223247.000000\n",
      "Name: sentence_count, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:24.145264Z",
     "start_time": "2025-04-17T06:43:01.118314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let us remove common stop words from the text before we count the words. Took help from chatgpt to understand how to use it\n",
    "def remove_common_stopwords(text):\n",
    "    #  standard English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # add common email-specific stop words\n",
    "    email_stop_words = {\n",
    "        'subject', 'from', 'to', 'cc', 'bcc', 'sent', 'received',\n",
    "        'date', 'time', 'regards', 'dear', 'sincerely', 'best',\n",
    "        'thanks', 'thank', 'you', 'yours', 'truly', 'hi', 'hello'\n",
    "    }\n",
    "\n",
    "    # combine both stop word sets\n",
    "    stop_words.update(email_stop_words)\n",
    "\n",
    "    # tokenize and remove stop words\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = ' '.join([word for word in word_tokens if word.lower() not in stop_words])\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# apply the function to the  DataFrame and replace the text column with the cleaned text\n",
    "df['text'] = df['text'].apply(remove_common_stopwords)\n"
   ],
   "id": "842660d7a5d7bc97",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.161876Z",
     "start_time": "2025-04-17T06:43:24.163434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lets analyze the text and come up with word count and urgency count, account related words Financial incentive word, credentialrelated, and threat\n",
    "def analyze_text_metrics(text):\n",
    "\n",
    "    # convert text to lowercase and handle potential null values\n",
    "    text_str = str(text).lower()\n",
    "\n",
    "    # Calculate total word count\n",
    "    total_words = len(text_str.split())\n",
    "\n",
    "    # Define term categories\n",
    "    urgency_terms = {\n",
    "        'urgent', 'immediate', 'immediately', 'action required', 'attention required', 'respond now',\n",
    "        'expires', 'expiring', 'deadline', 'limited time', 'act now', 'urgent action', 'click',\n",
    "        'here', 'now', 'free', 'offer', 'buy', 'purchase', 'donate', 'subscribe', 'register',\n",
    "        'sign up', 'get started', 'learn more'\n",
    "    }\n",
    "\n",
    "    account_terms = {\n",
    "        'verify', 'verification', 'authenticate', 'confirm', 'validate', 'reactivate',\n",
    "        'suspended', 'blocked', 'restricted', 'limited', 'unlock', 'secure', 'security',\n",
    "        'access', 'password', 'login', 'account', 'username', 'credential'\n",
    "    }\n",
    "\n",
    "    threat_terms = {\n",
    "        'terminate', 'deactivate', 'delete', 'removal', 'suspend', 'restriction',\n",
    "        'warning', 'risk', 'compromised', 'suspicious', 'unauthorized', 'disabled',\n",
    "        'cancelled', 'violation', 'breach', 'illegal'\n",
    "    }\n",
    "\n",
    "    financial_terms = {\n",
    "        'claim', 'prize', 'winner', 'won', 'reward', 'bonus', 'payment', 'refund',\n",
    "        'deposit', 'transfer', 'transaction', 'million', 'inheritance', 'lottery',\n",
    "        'cash', 'credit', 'bank', 'money', 'fund', 'balance'\n",
    "    }\n",
    "\n",
    "    official_terms = {\n",
    "        'official', 'authorized', 'authentication', 'notification', 'notice', 'alert',\n",
    "        'department', 'administration', 'support', 'service', 'helpdesk'\n",
    "    }\n",
    "\n",
    "    # Create dictionary with all counts\n",
    "    metrics = {\n",
    "        'total_word_count': total_words,\n",
    "        'urgency_terms_count': sum(term in text_str for term in urgency_terms),\n",
    "        'account_terms_count': sum(term in text_str for term in account_terms),\n",
    "        'threat_terms_count': sum(term in text_str for term in threat_terms),\n",
    "        'financial_terms_count': sum(term in text_str for term in financial_terms),\n",
    "        'official_terms_count': sum(term in text_str for term in official_terms)\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Apply the function to the DataFrame and expand the dictionary to columns\n",
    "df = pd.concat([\n",
    "    df,\n",
    "    df['text'].apply(analyze_text_metrics).apply(pd.Series)\n",
    "], axis=1)\n"
   ],
   "id": "2f54d4ba820bb6e9",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.175079Z",
     "start_time": "2025-04-17T06:43:27.170054Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "a6296d6aa5596a13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    text  type  \\\n",
       "0      : 6 . 1100 , disc : uniformitarianism , : 1086...     0   \n",
       "1      side * galicismos * * galicismo * spanish term...     0   \n",
       "2      : equistar deal tickets still available assist...     0   \n",
       "3      hot lil horny toy . one dream , open minded pe...     1   \n",
       "4      software incredibly low prices ( 86 % lower ) ...     1   \n",
       "...                                                  ...   ...   \n",
       "18626  lonely housewife always wanted lonely housewif...     1   \n",
       "18627  request submitted : access request anita . dup...     0   \n",
       "18628  : important - prc mtg dorn & john , discovered...     0   \n",
       "18629  press clippings - letter californian utilities...     0   \n",
       "18630                                              empty     1   \n",
       "\n",
       "       http_url_count  https_url_count  sentence_count  total_word_count  \\\n",
       "0                   0                0              10               144   \n",
       "1                   0                0               7                58   \n",
       "2                   0                0               8               231   \n",
       "3                   1                0               8                66   \n",
       "4                   0                0              13                85   \n",
       "...               ...              ...             ...               ...   \n",
       "18626               0                0               7                31   \n",
       "18627               0                0               9                84   \n",
       "18628               0                0              13               141   \n",
       "18629               0                0               1                29   \n",
       "18630               0                0               1                 1   \n",
       "\n",
       "       urgency_terms_count  account_terms_count  threat_terms_count  \\\n",
       "0                        1                    0                   0   \n",
       "1                        0                    0                   0   \n",
       "2                        2                    0                   0   \n",
       "3                        1                    0                   0   \n",
       "4                        0                    0                   0   \n",
       "...                    ...                  ...                 ...   \n",
       "18626                    0                    0                   0   \n",
       "18627                    1                    1                   0   \n",
       "18628                    0                    0                   0   \n",
       "18629                    0                    0                   0   \n",
       "18630                    0                    0                   0   \n",
       "\n",
       "       financial_terms_count  official_terms_count  \n",
       "0                          0                     0  \n",
       "1                          0                     0  \n",
       "2                          0                     0  \n",
       "3                          0                     0  \n",
       "4                          0                     0  \n",
       "...                      ...                   ...  \n",
       "18626                      0                     0  \n",
       "18627                      0                     0  \n",
       "18628                      1                     1  \n",
       "18629                      0                     0  \n",
       "18630                      0                     0  \n",
       "\n",
       "[18631 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>http_url_count</th>\n",
       "      <th>https_url_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>urgency_terms_count</th>\n",
       "      <th>account_terms_count</th>\n",
       "      <th>threat_terms_count</th>\n",
       "      <th>financial_terms_count</th>\n",
       "      <th>official_terms_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: 6 . 1100 , disc : uniformitarianism , : 1086...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>side * galicismos * * galicismo * spanish term...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>: equistar deal tickets still available assist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hot lil horny toy . one dream , open minded pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software incredibly low prices ( 86 % lower ) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18626</th>\n",
       "      <td>lonely housewife always wanted lonely housewif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18627</th>\n",
       "      <td>request submitted : access request anita . dup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18628</th>\n",
       "      <td>: important - prc mtg dorn &amp; john , discovered...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18629</th>\n",
       "      <td>press clippings - letter californian utilities...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18630</th>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18631 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.202864Z",
     "start_time": "2025-04-17T06:43:27.198895Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "c5cec6fef5c71186",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  type  http_url_count  \\\n",
       "0  : 6 . 1100 , disc : uniformitarianism , : 1086...     0               0   \n",
       "1  side * galicismos * * galicismo * spanish term...     0               0   \n",
       "2  : equistar deal tickets still available assist...     0               0   \n",
       "3  hot lil horny toy . one dream , open minded pe...     1               1   \n",
       "4  software incredibly low prices ( 86 % lower ) ...     1               0   \n",
       "\n",
       "   https_url_count  sentence_count  total_word_count  urgency_terms_count  \\\n",
       "0                0              10               144                    1   \n",
       "1                0               7                58                    0   \n",
       "2                0               8               231                    2   \n",
       "3                0               8                66                    1   \n",
       "4                0              13                85                    0   \n",
       "\n",
       "   account_terms_count  threat_terms_count  financial_terms_count  \\\n",
       "0                    0                   0                      0   \n",
       "1                    0                   0                      0   \n",
       "2                    0                   0                      0   \n",
       "3                    0                   0                      0   \n",
       "4                    0                   0                      0   \n",
       "\n",
       "   official_terms_count  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>http_url_count</th>\n",
       "      <th>https_url_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>urgency_terms_count</th>\n",
       "      <th>account_terms_count</th>\n",
       "      <th>threat_terms_count</th>\n",
       "      <th>financial_terms_count</th>\n",
       "      <th>official_terms_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: 6 . 1100 , disc : uniformitarianism , : 1086...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>side * galicismos * * galicismo * spanish term...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>: equistar deal tickets still available assist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hot lil horny toy . one dream , open minded pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software incredibly low prices ( 86 % lower ) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### We may use  the original text  to do any sentiment analysis but right now I am dropping the text columns and that way I will have only integer column and the target column ie type\n",
    "\n"
   ],
   "id": "343a895dc6850db2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.264454Z",
     "start_time": "2025-04-17T06:43:27.260187Z"
    }
   },
   "cell_type": "code",
   "source": "df.drop(columns=['text'], inplace=True)",
   "id": "c55e5c9c436f476e",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.302138Z",
     "start_time": "2025-04-17T06:43:27.294557Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "969fb5a089b5de08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18631 entries, 0 to 18630\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype\n",
      "---  ------                 --------------  -----\n",
      " 0   type                   18631 non-null  int64\n",
      " 1   http_url_count         18631 non-null  int64\n",
      " 2   https_url_count        18631 non-null  int64\n",
      " 3   sentence_count         18631 non-null  int64\n",
      " 4   total_word_count       18631 non-null  int64\n",
      " 5   urgency_terms_count    18631 non-null  int64\n",
      " 6   account_terms_count    18631 non-null  int64\n",
      " 7   threat_terms_count     18631 non-null  int64\n",
      " 8   financial_terms_count  18631 non-null  int64\n",
      " 9   official_terms_count   18631 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.311311Z",
     "start_time": "2025-04-17T06:43:27.308126Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "1a2a9c5a39bd6291",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18631, 10)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.322828Z",
     "start_time": "2025-04-17T06:43:27.319818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perform_univariate_analysis(df):\n",
    "\n",
    "    # calculate number of rows and columns for subplots\n",
    "    n_features = len(df.columns)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "    # create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6*n_rows))\n",
    "    fig.suptitle('Univariate Analysis of Features', fontsize=16, y=1.02)\n",
    "\n",
    "    # flatten axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    #create histograms and KDE plots for each feature\n",
    "    for idx, column in enumerate(df.columns):\n",
    "        # Histogram with KDE\n",
    "        sns.histplot(data=df, x=column, hue='type', multiple=\"stack\",\n",
    "                    kde=True, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Distribution of {column}')\n",
    "        axes[idx].set_xlabel(column)\n",
    "        axes[idx].set_ylabel('Count')\n",
    "\n",
    "    # remove empty subplots if any\n",
    "    for idx in range(len(df.columns), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "c2c49c6162a7b90c",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.337502Z",
     "start_time": "2025-04-17T06:43:27.330823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Method to do bivariate analysis\n",
    "\n",
    "def perform_bivariate_analysis(df):\n",
    "      # create correlation Matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlation_matrix = df.corr()\n",
    "    sns.heatmap(correlation_matrix,\n",
    "                annot=True,\n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                fmt='.2f',\n",
    "                square=True)\n",
    "    plt.title('Correlation Matrix of Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # pairplot with KDE\n",
    "    print(\"generating pairplot ...\")\n",
    "    sns.pairplot(df, hue='type', diag_kind='kde')\n",
    "    plt.show()\n",
    "\n",
    "    # violin plots\n",
    "    features = [col for col in df.columns if col != 'type']\n",
    "    n_features = len(features)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6*n_rows))\n",
    "    fig.suptitle('Violin Plots by Type', fontsize=16, y=1.02)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        sns.violinplot(data=df, x='type', y=feature, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{feature} by Type')\n",
    "\n",
    "    # remove empty subplots\n",
    "    for idx in range(len(features), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # generate box plots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6*n_rows))\n",
    "    fig.suptitle('Box Plots by Type', fontsize=16, y=1.02)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        sns.boxplot(data=df, x='type', y=feature, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{feature} by Type')\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(features), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "faee4908363fcb25",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.356637Z",
     "start_time": "2025-04-17T06:43:27.353841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perform_kde_analysis(df):\n",
    "    features = [col for col in df.columns if col != 'type']\n",
    "    n_features = len(features)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6*n_rows))\n",
    "    fig.suptitle('KDE Plots by Feature', fontsize=16, y=1.02)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        sns.kdeplot(data=df, x=feature, hue='type', ax=axes[idx])\n",
    "        axes[idx].set_title(f'KDE Plot of {feature}')\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(features), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "2b9301a0674ea9a4",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.368465Z",
     "start_time": "2025-04-17T06:43:27.364449Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "9471e0eac21827a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   type  http_url_count  https_url_count  sentence_count  total_word_count  \\\n",
       "0     0               0                0              10               144   \n",
       "1     0               0                0               7                58   \n",
       "2     0               0                0               8               231   \n",
       "3     1               1                0               8                66   \n",
       "4     1               0                0              13                85   \n",
       "\n",
       "   urgency_terms_count  account_terms_count  threat_terms_count  \\\n",
       "0                    1                    0                   0   \n",
       "1                    0                    0                   0   \n",
       "2                    2                    0                   0   \n",
       "3                    1                    0                   0   \n",
       "4                    0                    0                   0   \n",
       "\n",
       "   financial_terms_count  official_terms_count  \n",
       "0                      0                     0  \n",
       "1                      0                     0  \n",
       "2                      0                     0  \n",
       "3                      0                     0  \n",
       "4                      0                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>http_url_count</th>\n",
       "      <th>https_url_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>urgency_terms_count</th>\n",
       "      <th>account_terms_count</th>\n",
       "      <th>threat_terms_count</th>\n",
       "      <th>financial_terms_count</th>\n",
       "      <th>official_terms_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.395630Z",
     "start_time": "2025-04-17T06:43:27.393475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_phishing_email_Univariate_data(df):\n",
    "\n",
    "    print(\"Performing Univariate Analysis...\")\n",
    "    perform_univariate_analysis(df)\n"
   ],
   "id": "9acde219b0b763fb",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.423048Z",
     "start_time": "2025-04-17T06:43:27.420303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_phishing_email_Bivariate_data(df):\n",
    "\n",
    "    print(\"\\nPerforming KDE Analysis...\")\n",
    "    perform_kde_analysis(df)\n",
    "\n",
    "    print(\"\\nPerforming Bivariate Analysis...\")\n",
    "    perform_bivariate_analysis(df)\n",
    "\n"
   ],
   "id": "83e7cc112208ebb9",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.435600Z",
     "start_time": "2025-04-17T06:43:27.426876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a random sample of 1000 rows while maintaining class balance\n",
    "def create_balanced_sample(df, sample_size=1000, random_state=42):\n",
    "    # calculate the number of samples needed from each class\n",
    "    samples_per_class = sample_size // 2\n",
    "\n",
    "    # split the data by class\n",
    "    spam = df[df['type'] == 1]\n",
    "    non_spam = df[df['type'] == 0]\n",
    "\n",
    "    # sample equally from each class\n",
    "    spam_sample = spam.sample(n=samples_per_class, random_state=random_state)\n",
    "    non_spam_sample = non_spam.sample(n=samples_per_class, random_state=random_state)\n",
    "\n",
    "    # combine the samples\n",
    "    balanced_sample = pd.concat([spam_sample, non_spam_sample])\n",
    "\n",
    "    # chuffle the combined sample\n",
    "    balanced_sample = balanced_sample.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    return balanced_sample\n",
    "\n",
    "# create the balanced sample\n",
    "sampled_phishing_email_df = create_balanced_sample(df, sample_size= 10000, random_state=39)\n",
    "\n",
    "# verify the sample\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Sampled dataset shape:\", sampled_phishing_email_df.shape)\n",
    "print(\"\\nClass distribution in sample:\")\n",
    "print(sampled_phishing_email_df['type'].value_counts())\n",
    "\n"
   ],
   "id": "d2b2a9000c1fb637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (18631, 10)\n",
      "Sampled dataset shape: (10000, 10)\n",
      "\n",
      "Class distribution in sample:\n",
      "type\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.446435Z",
     "start_time": "2025-04-17T06:43:27.444740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#generate the graphs for Univariate analysis for the whole then use df but we will use sample\n",
    "#analyze_phishing_email_Univariate_data(sampled_phishing_email_df)"
   ],
   "id": "bd62f6d074ed7642",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.456312Z",
     "start_time": "2025-04-17T06:43:27.454356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#generate the graphs for Biivariate analysis for the whole then use df but we will use sample\n",
    "#analyze_phishing_email_Bivariate_data(sampled_phishing_email_df)"
   ],
   "id": "7a567581bf5de65c",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T06:43:27.465036Z",
     "start_time": "2025-04-17T06:43:27.463757Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "43e3fdaddb5a0f09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
